{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pkl_models = ('twitter_pkl', 'instagram_pkl', 'facebook_pkl', 'youtube_pkl', 'scaler')\n",
    "models = {}\n",
    "\n",
    "for pkl in pkl_models:\n",
    "    with open(pkl, \"rb\") as f:\n",
    "        models[pkl] = pickle.load(f)\n",
    "        models = {k.replace('_pkl', ''): v  \n",
    "         for k, v in models.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'twitter': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l1', random_state=None, solver='liblinear',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       " 'instagram': LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       " 'facebook': RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "             max_depth=21, max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=1950, n_jobs=-1,\n",
       "             oob_score=False, random_state=123, verbose=0, warm_start=False),\n",
       " 'youtube': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=98, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=4, min_samples_split=5,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=1460, n_jobs=-1,\n",
       "             oob_score=False, random_state=123, verbose=0, warm_start=False),\n",
       " 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_order = ['sex', 'party', 'emplnw', 'age', 'books1', 'pial12', 'pial11', 'pial5c', 'pial5b', 'snsint2',\n",
    "                 'device1b', 'device1c', 'smart2', 'intfreq', 'educ2', 'marital', 'books2a', 'books2b', 'books2c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'intfreq': '2', 'smart2': '2', 'snsint2': '2', 'device1b': '1', 'device1c': '1', \n",
    "     'pial5b': '5', 'pial5c': '2', 'pial11': '2', 'pial12': '3', 'books1': '33', 'books2a': '2', \n",
    "     'books2b': '2', 'books2c': '1', 'sex': '2', 'age': '23', 'marital': '3', 'educ2': '3', 'emplnw': '2', \n",
    "     'party': '2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_answers(d):\n",
    "    dict = np.float_([d[e] for e in feature_order])\n",
    "    print(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  2.  2. 23. 33.  3.  2.  2.  5.  2.  1.  1.  2.  2.  3.  3.  2.  2.\n",
      "  1.]\n"
     ]
    }
   ],
   "source": [
    "ordered_answers(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "answer_list=[]\n",
    "def ordered_answers2(d):\n",
    "    for name in feature_order:\n",
    "        for key, value in d.items():\n",
    "            if key == name:\n",
    "                answer_list.append(value)\n",
    "    print(list(np.float_(answer_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0, 2.0, 2.0, 23.0, 33.0, 3.0, 2.0, 2.0, 5.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "ordered_answers2(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[0.456666, 0.62000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_format(pred_answer):\n",
    "    conversion=[]\n",
    "    for n in pred_answer:\n",
    "        conversion.append(\"{:6.2f}%\".format(100*n).strip())\n",
    "    return conversion\n",
    "    \n",
    "# '{percent:.2%}'.format(percent=1.0/3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['45.67%', '62.00%']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_format(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
